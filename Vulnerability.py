# -*- coding: utf-8 -*-
import socket
import datetime
import urllib.request
import requests
from bs4 import BeautifulSoup
import re
import sys
from urllib import parse
from urllib.request import urlopen
import time
import os
from fpdf import FPDF

#데이터 평문 전송 취약점
def scan(domain):
    module_name = "Port Scan" #모듈 네임
    contents = "" #결과 내용을 저장할 변수
    is_cve = "Safe" #스캔 결과의 CVE(Common Vulnerabilties and Exposures) 상태

    comport = {"FTP": 21, "SMTP": 25, "HTTP": 80}
    #스캔할 포트와 해당 서비스를 정의하는 딕셔너리,FTP, SMTP, HTTP 서비스의 포트를 정의

    ad = domain
    adip = socket.gethostbyname(ad) #도메인을 ip주소로 변환

    for PN, port in comport.items(): #포트와 해당 서비스 반복적으로 스캔
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #소켓 생성
            result = s.connect_ex((adip, port)) #ip 주소와 포트로 연결 시도
            banner = s.recv(1024) #배너 정보 읽어오기

            if result == 0: #포트스캔 결과 성공
                contents += str(port) + "/tcp(" + str(PN) + ") Open "
                is_cve = "Risk" #CVE 상태를 RISK로 변환
            elif banner == b'': #연결에 실패하거나 응답없는 경우
                contents += str(port) + "/tcp(" + str(PN) + ") noservice\n"
            s.close()
        except:
            continue
    return (module_name, contents.strip(), is_cve) #모듈이름, 결과 내용, CVE 상태 담음

#관리자 페이지 노출
def adpage(domain):
    module_name = "Admin Page" #모듈 네임
    contents = "" #결과 내용을 저장할 변수
    is_cve = "Safe" #스캔 결과의 CVE(Common Vulnerabilties and Exposures) 상태

    page = ["/admin", "/manager", "/master", "/system", "/administart"] #예상되는 관리자 페이지 경로
    url = "http://" + domain
    for pages in page:
        try:
            req = urllib.request.urlopen(url + pages) #생성된 경로에 대한 요청 시도
            contents += (pages + " server exist\n") #content에 해당 페이지의 존재 여부 추가
            is_cve = "Risk" #CVE 상태를 RISK로 변환
        except: continue

    if is_cve == "Safe": #관리자페이 미존재
        contents += "no admin page found"
    return (module_name, contents.strip(), is_cve)

#HTTP 응답헤더에서 정보 추출
def get_header(domain):
    global req, header, dic, cve
    req = requests.get('http://'+domain) #주어진 도메인에 get요청 보내고 응답을 req에 저장
    header = req.headers #응답헤더 저장
    dic = {'server' : 'hidden', 'os' : 'hidden', 'lang' : 'hidden'}
    cve = {'server' : '', 'lang' : ''}
    if 'Server' in header:
        server=header['Server']
        s = server.split(' ')
        for i, a in enumerate(dic.keys()):
            dic[a] = s[i]
            if (len(s) < len(dic)):
                break
    else:
        pass

def check_cve(get_header): # CVE 를 확인하는 방법
    module_name = "Check CVE"
    contents = ""
    is_cve = "Safe"
    def cve1(key, contents, is_cve):
        r = requests.get('https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword='+str(dic[key]))
        # MITRE CVE 데이터베이스에서 CVE를 확인하기 위해 GET 요청
        soup = BeautifulSoup(r.text, 'html.parser')
        count_target = soup.find(class_="smaller") #CVE 개수 정보를 담고 있는 요소를 찾기
        cve[key] = count_target.find("b").text #해당 정보에 대한 CVE 개수를 추출
        list_result = str(soup.select("#TableWithRules")) #CVE 결과 테이블을 선택
        list_result = re.sub('<.+?>','',list_result,0).strip() # HTML 태그를 제거하고 앞뒤 공백 제거

        if len(list_result) > 26: #테이블의 존재여부 확인
            contents += 'https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword='+str(dic[key])
            is_cve = "Risk"
        return contents, is_cve

    if dic['server'] != 'hidden': #서버 정보가 숨겨져 있지 않은 경우
        contents, is_cve = cve1('server', contents, is_cve)
    if dic['lang'] != 'hidden': #언어 정보가 숨겨져 있지 않은경우
        contents, is_cve = cve1('lang', contents, is_cve)
    if contents == "": #결과 내용이 비어있는경우
        contents = "no cve found"
    return (module_name, contents.strip(), is_cve)

def help():
    print('Usage: ./main url')
    sys.exit(1)

def sqlinjection():
    sqlinjection_mysql = ['or 1=1--', '\' or 1=1--',
                          '\" or 1=1--',
                          '\' or \'1\'=\'1',
                          '\" or \"1\"=\"1']

    sqlinjection_oracle = ['\' or 1=1#', '\" or 1=1#',
                           'or 1=1#',
                           '\' or \'1\'=\'1',
                           '\" or \"1\"=\"1']
    return sqlinjection_mysql[1]


def send_post(data, next_url):
    is_cve = "Safe"
    header = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101Firefox / 66.0',
              'Accept': 'text / html, application / xhtml + xml, application / xml;q = 0.9, * / *;q = 0.8',
              'Accept - Language': 'en - US, en;q = 0.5',
              'Accept - Encoding': 'gzip, deflate', }
    resp = requests.post(next_url, data=data, headers=header)
    if "Sign Off" in resp.text:
        is_cve = "Risk"
    return (is_cve)

def get_domain(url):
    domainp = '^(https?:\/\/)?([\da-z\.-]+)'
    domain = re.compile(domainp).match(url).group()
    return domain

def sqltest(url):
    module_name = "SQL Injection"
    is_cve = "Safe"
    url = "http://" + url + "/login.jsp"
    r = requests.get(url).text
    soup = BeautifulSoup(r, 'html.parser')
    tags = soup.select("form input")

    idp = re.compile("id=\"[a-zA-Z]*id[a-z]*\"")
    for tag in tags:
        try:
            result = idp.search(str(tag)).group()
            id_value = result.replace("id=", "").replace("\"", "")
            break
        except AttributeError:
            result = None

    pw_value = soup.select('form input[type=password]')[0]['name']
    submit = soup.select('form input[type=submit]')
    submitp = re.compile("\"[a-zA-Z]*[L|l]ogin[a-zA-Z]*\"")
    subnetname = submitp.search(str(submit)).group().replace("\"", "")
    tags = soup.select("form")
    formp = re.compile("<form action=\"[a-zA-Z]*[L|l]ogin\"")
    actionvaluep = re.compile("\"[a-zA-Z]*\"")

    for tag in tags:
        result = formp.search(str(tag))
    if result != None:
        action_value = actionvaluep.search(result.group()).group().replace("\"", "")

    domain = get_domain(url)
    next_url = domain + "/" + action_value
    data = {id_value: sqlinjection(), pw_value: 'donecare'}
    contents = str(data)
    send_post(data, next_url)
    is_cve = send_post(data, next_url)
    return (module_name, contents.strip(), is_cve)

pages = set()
def getLinks(pageUrl):
    global pages
    html = urlopen(pageUrl)
    soup = BeautifulSoup(html, "html.parser")
    for link in soup.findAll("a"):
        if 'href' in link.attrs:
            pages.add(link.attrs['href'])
            if link.attrs['href'] not in pages:
                newPage = link.attrs['href']
                pages.add(newPage)
                getLinks(newPage)


def dicxss(url):
    module_name = "XSS"
    contents = ""
    is_cve = "Safe"

    url = "http://" + url
    getLinks(url) #주어진 URL에서 모든 페이지 링크 추출
    lst = list(pages) #추출된 모든 페이지 링크를 리스트로 담음

    dic = {}
    d = 0
    for i in lst:
        check = parse.urlparse(lst[int(d)]) #현재 링크를 파싱하여 URL 구성요소를 추출
        check.geturl()

        if check.query: #파싱된 URL에 쿼리 파라미터가 있는지 확인
            dic.update(parse.parse_qs(check.query)) #쿼리 파라미터와 값을 dic에 담음(parse_qs 함수는 쿼리 문자열을 파싱하여 딕셔너리로 반환)
        d += 1


    fname = "payloads.txt" #xss 공격에 사용할 페이로드가 포함된 파일 이름
    with open(fname) as f:
        content = f.readlines() #파일의 모든 줄을 읽어들임
    payloads = [x.strip() for x in content] #읽어들인 줄에서 양쪽 공백을 제거하고 payloads 리스트에 저장
    vuln = []
    for payload in payloads:
        for t in dic.keys(): #쿼리 파라미터 순회
            xss_url = url + "?" + t + "=" + payload #현재 키와 페이로드를 사용하여 xss 취약한 url 생성
            r = requests.get(xss_url) #생성한 취약한 url에 get요청
            if payload.lower() in r.text.lower(): #응답 텍스트에 소문자로 변환한 페이로드가 포함되어 있는지 확인
                if(payload not in vuln): #취약점 리스트에 현재 페이로드가 이미 존재하는지 확인
                    vuln.append(payload) #취약점 리스트에 현재 페이로드 추가
            else:
                continue
    if vuln: #취약점 존재한다면
        tmp_contents = "\n".join(vuln) #취약점 리스트의 요소를 줄바꿈으로 구분하여 하나의 문자열로 만듬
        contents += str(tmp_contents) #결과 내용에 취약점 문자열 추가
        is_cve = "Risk" #취약점 존재시 risk로 변환

    return (module_name, contents.strip(), is_cve)

def get_urldirectorypath(url):
    current_pagep = '\/[a-zA-Z0-9]*\.[a-zA-Z0-9]*$'
    path = re.sub(current_pagep, "", url)
    return path

def return_souporhtml(url, str):
    r = requests.get(url).text
    soup = BeautifulSoup(r, 'html.parser')
    if(str=="soup"):
        return soup
    elif(str=="html"):
        return soup.text

def regex_search(regex, str):
    p = re.compile(regex)
    s = p.search(str)
    return s

def dicrec(url):
    module_name = "Directory Listing"
    contents = ""
    is_cve = "Safe"
    c=0
    url = "http://"+url
    getLinks(url)
    lst = list(pages)
    for i in lst:
        toryurl = url+"/"+lst[int(c)]
        path = get_urldirectorypath(toryurl)
        html = return_souporhtml(path, "html")

        s = regex_search('Index of /', html)

    if s == None:
        contents = "This website is \"SAFE\" from Directory listing"
    else:
        contents = path
        is_cve = "Risk"
        c+=1
    return (module_name, contents.strip(), is_cve)

start = datetime.datetime.now()

def Westall(domain):
    results = []

    results.append(scan(domain))
    results.append(adpage(domain))
    get_header(domain)
    results.append(check_cve(get_header))
    results.append(dicrec(domain))
    results.append(dicxss(domain))
    results.append(sqltest(domain))
    return results

data = []
url = str(sys.argv[1])
uid = str(sys.argv[2])
data.extend(Westall(url))
filename = "cve_log_"+uid+".pdf"
title = 'Web Scan Report'
finish = datetime.datetime.now()
duration = finish - start

class PDF(FPDF):
    def header(self):
                self.set_font("Arial", size=24)
                self.cell(200, 20, txt="Website Vulnerability Scanner Report", ln=1, align="C")
                self.set_text_color(46, 138, 204)
                self.cell(20, 20, txt="Scan Information", ln=1)
                self.set_line_width(1)
                self.set_draw_color(255, 0, 0)
                self.line(10, 45, 200, 45)
                self.set_line_width(1)
                self.set_draw_color(0, 0, 0)
                self.set_text_color(0, 0, 0)
                self.set_font("Arial", size=11)
                self.cell(20, 5, txt="Website URL = " + url, ln=1)
                self.cell(10, 5, txt="Start Time = " + str(start), ln=1)
                self.cell(10, 5, txt="Finish Time = " + str(finish), ln=1)
                self.cell(10, 5, txt="Scan duration = " + str(duration), ln=1)
    def footer(self):
                self.set_y(-15)
                self.set_font('Arial', 'I', 8)
                self.set_text_color(128)
                self.cell(0, 10, 'Page ' + str(self.page_no()), 0, 0, 'C')

    def chapter_title(self, num, label):
                self.set_font('Arial', '', 12)
                self.set_fill_color(200, 220, 255)
                self.cell(0, 6, 'Chapter %d : %s' % (num, label), 0, 1, 'L', 1)
                self.ln(4)

    def chapter_body(self, spacing=2):
                global data

                self.cell(10, 20, ln=1, align="c")
                self.set_font("Arial", 'B', size=24)
                self.cell(10, 20, txt="List of tests performed (6/6)", ln=1, align="L")
                self.set_font("Arial", 'B', size=15)
                self.set_draw_color(0, 0, 0)
                self.set_line_width(0.5)
                col_width = self.w / 3.3
                row_height = self.font_size
                header = ('Type', 'Contents', 'Resulte')

                cellwidth = 110
                cellHeight = 5
                self.cell(40, cellHeight * 3, txt=header[0], border=1, align="C")
                self.cell(cellwidth, cellHeight * 3, txt=header[1], border=1, align="C")
                self.cell(40, cellHeight * 3, txt=header[2], border=1, ln=1, align="C")
                self.set_font("Arial", size=10)
                for i in range(6):
                    line = 1
                    if self.get_string_width(data[i][1]) < cellwidth:
                        line = 1

                    else:
                        textLength = len(data[i][1])
                        errMargin = 44
                        startChar = 0
                        maxChar = 0
                        textArray = []
                        tmpString = ""
                        st = data[i][1]
                        while (startChar < textLength):
                            while (self.get_string_width(tmpString) < (cellwidth - errMargin) and (startChar + maxChar) < textLength):
                                maxChar += 1
                                tmpString = st[startChar: maxChar]
                            startChar = startChar + maxChar
                            textArray.append(tmpString)
                            line += 1
                            maxChar = 0
                            tmpString = ""
                    self.cell(40, line * cellHeight, txt=data[i][0], border=1, ln=0, align="C")
                    x = self.get_x()
                    y = self.get_y()
                    self.multi_cell(cellwidth, cellHeight, txt=data[i][1], border=1)
                    self.set_xy(x + cellwidth, y)
                    self.cell(40, line * cellHeight, txt=data[i][2], border=1, ln=1, align="C")

    def print_chapter(self, num, title, name):
        self.add_page()
        self.chapter_title(num, title)
        self.chapter_body(name)

pdf = PDF()
pdf.set_title(title)
pdf.add_page()
pdf.chapter_body()
pdf.output(filename, 'F')